{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, List, Dict\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Residual Block with two convolutional layers and a shortcut connection.\n",
    "    Facilitates better gradient flow and allows for deeper networks.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride: int = 1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # Shortcut connection\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass for the residual block.\n",
    "        \"\"\"\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        shortcut = self.shortcut(x)\n",
    "        out += shortcut\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class GeometricRegularization(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements geometric regularization for CNN feature maps using differential geometry concepts.\n",
    "    This version includes improved numerical stability and better loss scaling.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lambda_area: float = 0.001, lambda_curv: float = 0.001):\n",
    "        super().__init__()\n",
    "        self.lambda_area = lambda_area\n",
    "        self.lambda_curv = lambda_curv\n",
    "        self.eps = 1e-6  # Increased epsilon for better numerical stability\n",
    "\n",
    "        # Instance normalization to normalize feature maps before regularization\n",
    "        self.instance_norm = nn.InstanceNorm2d(1, affine=False)\n",
    "\n",
    "    def compute_derivatives(self, feature_map: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Compute first derivatives using Sobel filters for better stability.\n",
    "        Args:\n",
    "            feature_map: Tensor of shape (B, C, H, W)\n",
    "        Returns:\n",
    "            du, dv: First derivatives in u and v directions\n",
    "        \"\"\"\n",
    "        B, C, H, W = feature_map.shape\n",
    "\n",
    "        # Sobel filters for better gradient computation\n",
    "        du_kernel = (\n",
    "            torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], device=feature_map.device)\n",
    "            .view(1, 1, 3, 3)\n",
    "            .repeat(C, 1, 1, 1)\n",
    "        )\n",
    "        dv_kernel = (\n",
    "            torch.tensor([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], device=feature_map.device)\n",
    "            .view(1, 1, 3, 3)\n",
    "            .repeat(C, 1, 1, 1)\n",
    "        )\n",
    "\n",
    "        # Convert kernels to feature map's dtype\n",
    "        du_kernel = du_kernel.to(feature_map.dtype)\n",
    "        dv_kernel = dv_kernel.to(feature_map.dtype)\n",
    "\n",
    "        # Compute gradients using convolution\n",
    "        padded = F.pad(feature_map, (1, 1, 1, 1), mode=\"reflect\")\n",
    "        du = F.conv2d(padded, du_kernel, groups=C) / 8.0\n",
    "        dv = F.conv2d(padded, dv_kernel, groups=C) / 8.0\n",
    "\n",
    "        return du, dv\n",
    "\n",
    "    def compute_second_derivatives(self, feature_map: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Compute second derivatives with improved stability using central differences.\n",
    "        Args:\n",
    "            feature_map: Tensor of shape (B, C, H, W)\n",
    "        Returns:\n",
    "            duu, dvv, duv: Second derivatives\n",
    "        \"\"\"\n",
    "        padded = F.pad(feature_map, (2, 2, 2, 2), mode=\"reflect\")\n",
    "\n",
    "        # Second derivatives using central differences\n",
    "        duu = (padded[:, :, 2:-2, 4:] - 2 * padded[:, :, 2:-2, 2:-2] + padded[:, :, 2:-2, :-4]) / 4.0\n",
    "        dvv = (padded[:, :, 4:, 2:-2] - 2 * padded[:, :, 2:-2, 2:-2] + padded[:, :, :-4, 2:-2]) / 4.0\n",
    "        duv = (\n",
    "            padded[:, :, 3:-1, 3:-1] - padded[:, :, 3:-1, 1:-3] - padded[:, :, 1:-3, 3:-1] + padded[:, :, 1:-3, 1:-3]\n",
    "        ) / 4.0\n",
    "\n",
    "        return duu, dvv, duv\n",
    "\n",
    "    def compute_metric_tensor(\n",
    "        self, du: torch.Tensor, dv: torch.Tensor\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Compute components of the metric tensor (first fundamental form) with improved stability.\n",
    "        Args:\n",
    "            du, dv: First derivatives\n",
    "        Returns:\n",
    "            guu, gvv, guv: Metric tensor components\n",
    "        \"\"\"\n",
    "        # Add small constant for stability\n",
    "        guu = torch.sum(du * du, dim=1) + self.eps\n",
    "        gvv = torch.sum(dv * dv, dim=1) + self.eps\n",
    "        guv = torch.sum(du * dv, dim=1)\n",
    "\n",
    "        return guu, gvv, guv\n",
    "\n",
    "    def compute_mean_curvature(\n",
    "        self,\n",
    "        du: torch.Tensor,\n",
    "        dv: torch.Tensor,\n",
    "        duu: torch.Tensor,\n",
    "        dvv: torch.Tensor,\n",
    "        duv: torch.Tensor,\n",
    "        guu: torch.Tensor,\n",
    "        gvv: torch.Tensor,\n",
    "        guv: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute mean curvature with improved numerical stability.\n",
    "        Uses the Laplacian formulation that works for feature maps of any dimensionality.\n",
    "        \"\"\"\n",
    "        # Normalize derivatives for better numerical stability\n",
    "        du_norm = torch.sqrt(torch.sum(du * du, dim=1) + self.eps)\n",
    "        dv_norm = torch.sqrt(torch.sum(dv * dv, dim=1) + self.eps)\n",
    "\n",
    "        du = du / (du_norm.unsqueeze(1) + self.eps)\n",
    "        dv = dv / (dv_norm.unsqueeze(1) + self.eps)\n",
    "\n",
    "        # Compute mean curvature using normalized derivatives\n",
    "        det_g = guu * gvv - guv * guv + self.eps\n",
    "        H = (\n",
    "            gvv * torch.sum(duu * du, dim=1) + guu * torch.sum(dvv * dv, dim=1) - 2 * guv * torch.sum(duv * du, dim=1)\n",
    "        ) / (2 * torch.sqrt(det_g))\n",
    "\n",
    "        return H\n",
    "\n",
    "    def forward(self, feature_map: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute geometric regularization loss with improved stability and normalization.\n",
    "        Args:\n",
    "            feature_map: Tensor of shape (B, C, H, W)\n",
    "        Returns:\n",
    "            loss: Geometric regularization loss\n",
    "        \"\"\"\n",
    "        # Normalize each feature map channel-wise\n",
    "        # Assuming feature_map shape is (B, C, H, W)\n",
    "        B, C, H, W = feature_map.shape\n",
    "        # Reshape to (B*C, 1, H, W) for instance normalization\n",
    "        feature_map = feature_map.view(B * C, 1, H, W)\n",
    "        feature_map = self.instance_norm(feature_map)\n",
    "        # Reshape back to (B, C, H, W)\n",
    "        feature_map = feature_map.view(B, C, H, W)\n",
    "\n",
    "        # Compute derivatives\n",
    "        du, dv = self.compute_derivatives(feature_map)\n",
    "        duu, dvv, duv = self.compute_second_derivatives(feature_map)\n",
    "\n",
    "        # Compute metric tensor\n",
    "        guu, gvv, guv = self.compute_metric_tensor(du, dv)\n",
    "\n",
    "        # Compute area term with gradient clipping\n",
    "        det_g = guu * gvv - guv * guv + self.eps\n",
    "        area_loss = torch.sqrt(det_g).mean()\n",
    "        area_loss = torch.clamp(area_loss, max=10.0)\n",
    "\n",
    "        # Compute mean curvature with stability improvements\n",
    "        H = self.compute_mean_curvature(du, dv, duu, dvv, duv, guu, gvv, guv)\n",
    "        curvature_loss = torch.abs(H).mean()\n",
    "        curvature_loss = torch.clamp(curvature_loss, max=10.0)\n",
    "\n",
    "        # Combine losses with proper scaling\n",
    "        total_loss = self.lambda_area * area_loss + self.lambda_curv * curvature_loss\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "\n",
    "class BaseCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Residual CNN architecture serving as the baseline model.\n",
    "    Includes residual connections for better gradient flow and feature reuse.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes: int = 10):\n",
    "        super(BaseCNN, self).__init__()\n",
    "        # Define layers using ResidualBlock\n",
    "        self.layer1 = ResidualBlock(3, 64, stride=1)  # Output: 64 x 32 x 32\n",
    "        self.layer2 = ResidualBlock(64, 128, stride=2)  # Output: 128 x 16 x 16\n",
    "        self.layer3 = ResidualBlock(128, 256, stride=2)  # Output: 256 x 8 x 8\n",
    "\n",
    "        # Pooling and dropout\n",
    "        self.pool = nn.AdaptiveAvgPool2d((4, 4))  # Output: 256 x 4 x 4\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(256 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, List[torch.Tensor]]:\n",
    "        \"\"\"\n",
    "        Forward pass for the BaseCNN.\n",
    "        Returns:\n",
    "            - Output logits\n",
    "            - List of feature maps from different layers\n",
    "        \"\"\"\n",
    "        feature_maps = []\n",
    "\n",
    "        x = self.layer1(x)  # 64 x 32 x 32\n",
    "        feature_maps.append(x)\n",
    "\n",
    "        x = self.layer2(x)  # 128 x 16 x 16\n",
    "        feature_maps.append(x)\n",
    "\n",
    "        x = self.layer3(x)  # 256 x 8 x 8\n",
    "        feature_maps.append(x)\n",
    "\n",
    "        x = self.pool(x)  # 256 x 4 x 4\n",
    "        x = x.view(-1, 256 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x, feature_maps\n",
    "\n",
    "\n",
    "class GeometricCNN(BaseCNN):\n",
    "    \"\"\"\n",
    "    CNN with geometric regularization.\n",
    "    Extends BaseCNN to include geometric regularization on feature maps.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int = 10,\n",
    "        lambda_area: float = 0.001,\n",
    "        lambda_curv: float = 0.001,\n",
    "    ):\n",
    "        super(GeometricCNN, self).__init__(num_classes)\n",
    "        self.geo_reg = GeometricRegularization(lambda_area, lambda_curv)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, List[torch.Tensor]]:\n",
    "        \"\"\"\n",
    "        Forward pass for GeometricCNN.\n",
    "        Returns:\n",
    "            - Output logits\n",
    "            - List of feature maps from different layers for geometric regularization\n",
    "        \"\"\"\n",
    "        feature_maps = []\n",
    "\n",
    "        x = self.layer1(x)  # 64 x 32 x 32\n",
    "        feature_maps.append(x)\n",
    "\n",
    "        x = self.layer2(x)  # 128 x 16 x 16\n",
    "        feature_maps.append(x)\n",
    "\n",
    "        x = self.layer3(x)  # 256 x 8 x 8\n",
    "        feature_maps.append(x)\n",
    "\n",
    "        x = self.pool(x)  # 256 x 4 x 4\n",
    "        x = x.view(-1, 256 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x, feature_maps\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    \"\"\"\n",
    "    Handles model training and evaluation with improved stability and monitoring.\n",
    "    Includes learning rate scheduling, gradient clipping, and early stopping.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        train_loader: DataLoader,\n",
    "        val_loader: DataLoader,\n",
    "        device: torch.device,\n",
    "        base_model: nn.Module = None,\n",
    "    ):\n",
    "        self.model = model.to(device)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.device = device\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Optimizer and scheduler setup based on model type\n",
    "        base_lr = 0.001\n",
    "        if isinstance(model, GeometricCNN):\n",
    "            self.optimizer = optim.AdamW(\n",
    "                model.parameters(),\n",
    "                lr=base_lr * 0.5,\n",
    "                weight_decay=1e-4,\n",
    "                amsgrad=True,\n",
    "            )\n",
    "            self.scheduler = optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=15, eta_min=1e-6)\n",
    "        else:\n",
    "            self.optimizer = optim.Adam(model.parameters(), lr=base_lr)\n",
    "            self.scheduler = optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=50, eta_min=1e-6)\n",
    "\n",
    "        # Training state\n",
    "        self.metrics = defaultdict(list)\n",
    "        self.best_accuracy = 0.0\n",
    "        self.patience = 0\n",
    "        self.max_patience = 15\n",
    "        self.clip_value = 1.0\n",
    "\n",
    "        # Loss scaling for geometric regularization\n",
    "        self.geo_weight_scheduler = lambda epoch: min(1.0, epoch / 10.0)\n",
    "\n",
    "        self.base_model = base_model.to(device) if base_model else None\n",
    "\n",
    "    def train_epoch(self) -> Tuple[float, float]:\n",
    "        \"\"\"Train for one epoch with gradient clipping and loss scaling\"\"\"\n",
    "        self.model.train()\n",
    "        running_task_loss = 0.0\n",
    "        running_geo_loss = 0.0\n",
    "        current_epoch = len(self.metrics[\"epoch\"])\n",
    "\n",
    "        for inputs, labels in self.train_loader:\n",
    "            inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            if isinstance(self.model, GeometricCNN):\n",
    "                # Forward pass with geometric regularization\n",
    "                outputs, feature_maps = self.model(inputs)\n",
    "                task_loss = self.criterion(outputs, labels)\n",
    "\n",
    "                # Compute geometric loss with progressive scaling\n",
    "                geo_weight = self.geo_weight_scheduler(current_epoch)\n",
    "                geo_loss = sum(self.model.geo_reg(fm) for fm in feature_maps)\n",
    "                loss = task_loss + geo_weight * geo_loss\n",
    "\n",
    "                running_task_loss += task_loss.item()\n",
    "                running_geo_loss += geo_loss.item()\n",
    "            else:\n",
    "                # Forward pass for BaseCNN\n",
    "                outputs, feature_maps = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                running_task_loss += loss.item()\n",
    "\n",
    "            # Backward pass with gradient clipping\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.clip_value)\n",
    "            self.optimizer.step()\n",
    "\n",
    "        # Compute average losses\n",
    "        avg_task_loss = running_task_loss / len(self.train_loader)\n",
    "        avg_geo_loss = running_geo_loss / len(self.train_loader) if isinstance(self.model, GeometricCNN) else 0.0\n",
    "\n",
    "        return avg_task_loss, avg_geo_loss\n",
    "\n",
    "    def validate(self) -> Tuple[float, float]:\n",
    "        \"\"\"Compute validation accuracy and loss\"\"\"\n",
    "        self.model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        val_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in self.val_loader:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "\n",
    "                outputs, _ = self.model(inputs)\n",
    "\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # Compute accuracy\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        # Calculate final metrics\n",
    "        accuracy = 100.0 * correct / total\n",
    "        avg_val_loss = val_loss / len(self.val_loader)\n",
    "\n",
    "        # Update best accuracy and patience for early stopping\n",
    "        if accuracy > self.best_accuracy:\n",
    "            self.best_accuracy = accuracy\n",
    "            self.patience = 0\n",
    "        else:\n",
    "            self.patience += 1\n",
    "\n",
    "        return accuracy, avg_val_loss\n",
    "\n",
    "    def train(self, epochs: int = 15) -> Dict[str, List[float]]:\n",
    "        \"\"\"\n",
    "        Complete training process with comprehensive monitoring and visualization\n",
    "        Args:\n",
    "            epochs: Number of training epochs\n",
    "        Returns:\n",
    "            Dictionary containing training metrics\n",
    "        \"\"\"\n",
    "        for epoch in range(epochs):\n",
    "            # Training phase with loss computation\n",
    "            train_loss, geo_loss = self.train_epoch()\n",
    "            accuracy, val_loss = self.validate()\n",
    "\n",
    "            # Update learning rate scheduler\n",
    "            self.scheduler.step()\n",
    "\n",
    "            # Store all metrics for plotting\n",
    "            self.metrics[\"epoch\"].append(epoch)\n",
    "            self.metrics[\"train_loss\"].append(train_loss)\n",
    "            self.metrics[\"val_loss\"].append(val_loss)\n",
    "            self.metrics[\"val_accuracy\"].append(accuracy)\n",
    "            if isinstance(self.model, GeometricCNN):\n",
    "                self.metrics[\"geo_loss\"].append(geo_loss)\n",
    "\n",
    "            # Print detailed training progress\n",
    "            print(f\"\\nEpoch {epoch + 1}/{epochs}:\")\n",
    "            print(f\"Training Loss: {train_loss:.3f}\")\n",
    "            if isinstance(self.model, GeometricCNN):\n",
    "                print(f\"Geometric Loss: {geo_loss:.3f}\")\n",
    "            print(f\"Validation Loss: {val_loss:.3f}\")\n",
    "            print(f\"Validation Accuracy: {accuracy:.2f}%\")\n",
    "            print(f'Learning Rate: {self.optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "\n",
    "            # Check for early stopping\n",
    "            if self.patience >= self.max_patience:\n",
    "                print(f\"\\nEarly stopping triggered after {epoch + 1} epochs\")\n",
    "                print(f\"Best validation accuracy: {self.best_accuracy:.2f}%\")\n",
    "                break\n",
    "\n",
    "        # Create final visualizations\n",
    "        self.plot_training_metrics()\n",
    "\n",
    "        return self.metrics\n",
    "\n",
    "    def plot_training_metrics(self):\n",
    "        \"\"\"\n",
    "        Create comprehensive visualization of training metrics.\n",
    "        Includes loss curves, accuracy progression, and geometric metrics if applicable.\n",
    "        \"\"\"\n",
    "        # Determine number of subplots based on model type\n",
    "        n_plots = 3 if isinstance(self.model, GeometricCNN) else 2\n",
    "        fig, axes = plt.subplots(1, n_plots, figsize=(6 * n_plots, 5))\n",
    "        fig.suptitle(\"Training Progress\", fontsize=16, y=1.05)\n",
    "\n",
    "        epochs = self.metrics[\"epoch\"]\n",
    "\n",
    "        # Plot training and validation loss\n",
    "        axes[0].plot(epochs, self.metrics[\"train_loss\"], \"b-\", label=\"Training Loss\")\n",
    "        axes[0].plot(epochs, self.metrics[\"val_loss\"], \"r-\", label=\"Validation Loss\")\n",
    "        axes[0].set_title(\"Loss Curves\")\n",
    "        axes[0].set_xlabel(\"Epoch\")\n",
    "        axes[0].set_ylabel(\"Loss\")\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True)\n",
    "\n",
    "        # Plot validation accuracy\n",
    "        axes[1].plot(epochs, self.metrics[\"val_accuracy\"], \"g-\")\n",
    "        axes[1].set_title(\"Validation Accuracy\")\n",
    "        axes[1].set_xlabel(\"Epoch\")\n",
    "        axes[1].set_ylabel(\"Accuracy (%)\")\n",
    "        axes[1].grid(True)\n",
    "\n",
    "        # Plot geometric loss if applicable\n",
    "        if isinstance(self.model, GeometricCNN):\n",
    "            axes[2].plot(epochs, self.metrics[\"geo_loss\"], \"m-\")\n",
    "            axes[2].set_title(\"Geometric Regularization Loss\")\n",
    "            axes[2].set_xlabel(\"Epoch\")\n",
    "            axes[2].set_ylabel(\"Loss\")\n",
    "            axes[2].grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_training_comparison(base_metrics: Dict[str, List[float]], geo_metrics: Dict[str, List[float]]) -> None:\n",
    "    \"\"\"\n",
    "    Create side-by-side comparison of base CNN and geometric CNN performance.\n",
    "\n",
    "    Args:\n",
    "        base_metrics: Training metrics from base CNN\n",
    "        geo_metrics: Training metrics from geometric CNN\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    fig.suptitle(\"Performance Comparison: Base CNN vs Geometric CNN\", fontsize=16, y=1.05)\n",
    "\n",
    "    epochs = range(1, len(base_metrics[\"train_loss\"]) + 1)\n",
    "\n",
    "    # Plot training loss comparison\n",
    "    axes[0].plot(epochs, base_metrics[\"train_loss\"], \"b-\", label=\"Base CNN\")\n",
    "    axes[0].plot(epochs, geo_metrics[\"train_loss\"], \"r-\", label=\"Geometric CNN\")\n",
    "    axes[0].set_title(\"Training Loss\")\n",
    "    axes[0].set_xlabel(\"Epoch\")\n",
    "    axes[0].set_ylabel(\"Loss\")\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # Plot validation accuracy comparison\n",
    "    axes[1].plot(epochs, base_metrics[\"val_accuracy\"], \"b-\", label=\"Base CNN\")\n",
    "    axes[1].plot(epochs, geo_metrics[\"val_accuracy\"], \"r-\", label=\"Geometric CNN\")\n",
    "    axes[1].set_title(\"Validation Accuracy\")\n",
    "    axes[1].set_xlabel(\"Epoch\")\n",
    "    axes[1].set_ylabel(\"Accuracy (%)\")\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def compare_activation_maps(\n",
    "    base_model: nn.Module, geo_model: nn.Module, test_loader: DataLoader, device: torch.device, num_maps: int = 5\n",
    "):\n",
    "    \"\"\"\n",
    "    Randomly selects a sample image from the test set and compares 5 activation maps from the first and second layers\n",
    "    of BaseCNN and GeometricCNN.\n",
    "\n",
    "    Args:\n",
    "        base_model: Trained BaseCNN model\n",
    "        geo_model: Trained GeometricCNN model\n",
    "        test_loader: DataLoader for the test set\n",
    "        device: Computation device\n",
    "        num_maps: Number of activation maps to compare per layer\n",
    "    \"\"\"\n",
    "    base_model.eval()\n",
    "    geo_model.eval()\n",
    "\n",
    "    # Get a random sample from the test set\n",
    "    try:\n",
    "        sample_inputs, _ = next(iter(test_loader))\n",
    "    except StopIteration:\n",
    "        print(\"Test loader is empty. Skipping activation maps comparison.\")\n",
    "        return\n",
    "\n",
    "    sample_idx = random.randint(0, sample_inputs.size(0) - 1)\n",
    "    sample_input = sample_inputs[sample_idx].unsqueeze(0).to(device)\n",
    "\n",
    "    # Get the image before normalization for display\n",
    "    inv_normalize = transforms.Normalize(\n",
    "        mean=[-0.4914 / 0.2023, -0.4822 / 0.1994, -0.4465 / 0.2010], std=[1 / 0.2023, 1 / 0.1994, 1 / 0.2010]\n",
    "    )\n",
    "    sample_img = inv_normalize(sample_input.squeeze(0)).cpu().numpy()\n",
    "    sample_img = np.transpose(sample_img, (1, 2, 0))\n",
    "    sample_img = np.clip(sample_img, 0, 1)\n",
    "\n",
    "    # Get feature maps\n",
    "    with torch.no_grad():\n",
    "        _, base_feature_maps = base_model(sample_input)\n",
    "        _, geo_feature_maps = geo_model(sample_input)\n",
    "\n",
    "    # Layers to compare (first and second layers)\n",
    "    layers = [\"Layer 1\", \"Layer 2\"]\n",
    "    layer_indices = [0, 1]  # Corresponding to layer1 and layer2\n",
    "\n",
    "    for layer_idx, layer_name in zip(layer_indices, layers):\n",
    "        base_fmap = base_feature_maps[layer_idx]  # (1, C, H, W)\n",
    "        geo_fmap = geo_feature_maps[layer_idx]  # (1, C, H, W)\n",
    "\n",
    "        # Select 5 random channels\n",
    "        num_channels = base_fmap.size(1)\n",
    "        if num_channels < num_maps:\n",
    "            selected_channels = list(range(num_channels))\n",
    "        else:\n",
    "            selected_channels = random.sample(range(num_channels), num_maps)\n",
    "\n",
    "        fig, axes = plt.subplots(num_maps + 1, 3, figsize=(15, 5 * (num_maps + 1)))\n",
    "        fig.suptitle(f\"{layer_name} Activation Maps Comparison\", fontsize=16, y=1.02)\n",
    "\n",
    "        # Display Reference Image\n",
    "        axes[0, 0].imshow(sample_img)\n",
    "        axes[0, 0].axis(\"off\")\n",
    "        axes[0, 0].set_title(\"Reference Image\")\n",
    "\n",
    "        # Titles for Base and Geometric CNN\n",
    "        axes[0, 1].imshow(np.zeros((10, 10)), cmap=\"gray\")  # Placeholder\n",
    "        axes[0, 1].axis(\"off\")\n",
    "        axes[0, 1].set_title(\"Base CNN\")\n",
    "\n",
    "        axes[0, 2].imshow(np.zeros((10, 10)), cmap=\"gray\")  # Placeholder\n",
    "        axes[0, 2].axis(\"off\")\n",
    "        axes[0, 2].set_title(\"Geometric CNN\")\n",
    "\n",
    "        for i, channel in enumerate(selected_channels, start=1):\n",
    "            # BaseCNN activation map\n",
    "            base_feat = base_fmap[0, channel].cpu().numpy()\n",
    "            base_feat_norm = (base_feat - base_feat.min()) / (base_feat.max() - base_feat.min() + 1e-8)\n",
    "            axes[i, 1].imshow(base_feat_norm, cmap=\"viridis\")\n",
    "            axes[i, 1].axis(\"off\")\n",
    "            axes[i, 1].set_title(f\"Base CNN - Channel {channel}\")\n",
    "\n",
    "            # GeometricCNN activation map\n",
    "            geo_feat = geo_fmap[0, channel].cpu().numpy()\n",
    "            geo_feat_norm = (geo_feat - geo_feat.min()) / (geo_feat.max() - geo_feat.min() + 1e-8)\n",
    "            axes[i, 2].imshow(geo_feat_norm, cmap=\"viridis\")\n",
    "            axes[i, 2].axis(\"off\")\n",
    "            axes[i, 2].set_title(f\"Geometric CNN - Channel {channel}\")\n",
    "\n",
    "        # Hide the reference image's other columns\n",
    "        for i in range(1, num_maps + 1):\n",
    "            axes[i, 0].axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(17)\n",
    "np.random.seed(17)\n",
    "random.seed(17)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Data preprocessing\n",
    "transform_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_test = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform_train)\n",
    "trainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform_test)\n",
    "testloader = DataLoader(testset, batch_size=128, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "# Initialize Base CNN\n",
    "print(\"\\nTraining Base CNN...\")\n",
    "base_cnn = BaseCNN()\n",
    "base_trainer = Trainer(base_cnn, trainloader, testloader, device)\n",
    "base_metrics = base_trainer.train(epochs=15)\n",
    "\n",
    "# Initialize Geometric CNN with Residual Connections\n",
    "print(\"\\nTraining Geometric CNN...\")\n",
    "geo_cnn = GeometricCNN(lambda_area=0.01, lambda_curv=0.1)\n",
    "geo_trainer = Trainer(geo_cnn, trainloader, testloader, device, base_model=base_cnn)\n",
    "geo_metrics = geo_trainer.train(epochs=15)\n",
    "\n",
    "# Plot performance comparison\n",
    "plot_training_comparison(base_metrics, geo_metrics)\n",
    "\n",
    "# Compare Activation Maps\n",
    "compare_activation_maps(base_cnn, geo_cnn, testloader, device, num_maps=5)\n",
    "\n",
    "# Print final results\n",
    "print(\"\\nFinal Results:\")\n",
    "print(f\"Base CNN - Best Validation Accuracy: {base_trainer.best_accuracy:.2f}%\")\n",
    "print(f\"Geometric CNN - Best Validation Accuracy: {geo_trainer.best_accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
